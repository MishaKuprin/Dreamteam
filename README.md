# Big Data проект по симуляции работы Японского телеком-оператора
## Описание
Работа любого телеком-оператора неизбежно сопряжена с необходимостью работы с огромным количеством данных. В эпоху интернета один пользователь может соверашть большое количество действий, будь то звонки, отправка смс, выход в интернет и др. А таких пользователей может быть несколько миллионов и телеком-операторы вынуждены хранить и обрабатывать данные каждого клиента. Для облегчения этой задачи и используются технологии Big Data. В рамках данного проекта была разработана инфраструктура, симулирующая реальную работу Big Data отдела телеком-оператора в Японии.
<img src='https://vd-tv.ru/wp-content/uploads/2020/11/hjhgf.png'>

## Результаты
В результате работы над проектом была разработана система автоматической генерации, хранения и обработки данных абонентов Японского телеком-оператора. Система также была развернута на базе виртуальной машины Ubuntu и помещена в контейнер Docker. Вот как в итоге выглядела схема организации хранилища и обработки данных:
<img src='https://drive.google.com/uc?export=view&id=13cX0gwKxETAgbG32iI0ebMlIYt7bHnM3'>

На основе наших сгенерированных и обработанных данных мы составили Дашборд компании средствами Yandex DataLens (см. [Dashboard](https://datalens.yandex/8t46st33d95s0)).

## Этапы проекта
1. Исследование Японского рынка телекоммуникационных услуг;
2. Демографическая, половозрастная, префектурная и другие сегментации населения;
3. Разработка библиотеки для генерации синтетических данных;
4. Разработка облочного хранилища;
5. Разработка автоматических обработчиков данных средствами Airflow и Spark;
6. Создание витрин данных по заказу условных маркетологов и бизнес-аналитиков;
7. Развертывание контейнерного сервера на базе Ubuntu с помощью Docker;
8. Создание дашборда для аналитики средствами Yandex DataLens.
<img src='https://drive.google.com/uc?export=view&id=16ZM1VlM2PYUtkHqGLRcWXJaOzKXMcwN1'>

## Генерация данных
Чтобы синтетические данные были похожи на реальные, на сколько это возможно, мы провели исследование рынка телекоммуникационных услуг в Японии. За основу брались некоторые самые популярные телеком-операторы (например, NTT docomo — крупнейший японский оператор мобильной связи, по состоянию на апрель 2010 года количество абонентов превышает 56 млн человек), их тарифы, цены и услуги. Затем проводился сбор статистики по разным критериям среди населения Японии такие, как процентное распределение населения по префектурам, половозрастное распределение, предпочтения возрастных групп и так далее. На основе собранной информации была разработана библиотека, способная генерировать пользователей, их тарифы и продукты и все вытекающие из этого данные (звонки, подписки, смс, интернет и многое другое, подробнее см. [Group2 BigData GoogleDoc](https://docs.google.com/document/d/1wQDWgiQnZdVRrk51Ou_Jz6B7dNl30mfD6yzAJvGkbj0/edit?usp=sharing)).

В итоге ER-диаграмма данных имела следующий вид:
<img src='https://drive.google.com/uc?export=view&id=1sGPQC2IYy3uRYSO2BQAyMhrbbSX_-Rj6'>

## Облачное хранилище и обработка данных
Для хранения большого объема данных мы воспользовались сервисами Google Drive и Google Cloud. Сгенерированные данные загружались в облачное хранилище, откуда выгружались средствами Airflow в RAW слой для последующей обработки. Обработчик Airflow — удобный инструмент для обработки сложных данных, с помощью которого была разработана автоматическая обработка сырых данных и привидение их к виду, необходимому для удобной работы, например, бизнес-аналитиков.
<img src='https://drive.google.com/uc?export=view&id=1SMUUsi-qPLdxk_jSWzUy4U_xJ2A0DXs_'>

Вот как в итоге выглядела схема организации хранилища и обработки данных:
<img src='https://drive.google.com/uc?export=view&id=13cX0gwKxETAgbG32iI0ebMlIYt7bHnM3'>

Также, была произведена симуляция кластерной обработки данных с помощью Spark:
<img src='https://drive.google.com/uc?export=view&id=18GjWl4HW60MV571hH-GhiYaRIJe_Djx7'>

## Витрины данных
Витрина данных — подмножество хранилища данных, представляющее собой массив тематической, узконаправленной информации, который позволяет, например, более эффективно проводить промоакции. В рамках проекта нам поступил заказ от условного заказчика из отдела маркетинга, на сбор двух витрин данных. Первая должна была предостовлять всю информацию о клиентах, которая может быть полезна при проведении следующих промоакций: предложение нового тарифа, предложение аддона, групповые тарифы (см. [Data Mart 1](https://docs.google.com/spreadsheets/d/1orwBjO_rse6HZjRKZYSNGh601qPokFjrbJS4tSwMml8/edit?usp=sharing)). Вторая позволяла вычислять очень важный показатель для оценки доходов компании — ARPU (показатель, используемый телекоммуникационными компаниями и означающий средний доход в расчёте на одного абонента. Является одним из показателей, характеризующих успешность бизнеса компании) за расчётный период, текущий и по регионам.

## Сервер
Вся система была перенесена сервер виртуальной машины Ubuntu и помещена в Docker контейнер для возможности развертывания в облачном хранилище.

## Дашборд
Для оперативной аналитики ситуации в любой крупной компании используются Дашборды. В них собрана вся необходимая информация о текущем состоянии дохода, оттока/притока клиентов и многое другое. На основе наших сгенерированных и обработанных данных мы составили Дашборд компании средствами Yandex DataLens (см. [Dashboard](https://datalens.yandex/8t46st33d95s0)).
